<pre>
# Paper
Show and Tell: image captioning open sourced in TensorFlow | Google Research Blog 
https://research.googleblog.com/2016/09/show-and-tell-image-captioning-open.html

Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge
https://arxiv.org/abs/1609.06647

Google researchers teach AIs to see the important parts of images — and tell you about them
https://techcrunch.com/2016/06/28/google-researchers-teach-ais-to-see-the-important-parts-of-images-and-tell-you-about-them/

Discovering the physical parts of an articulated object class from multiple videos
http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Del_Pero_Discovering_the_Physical_CVPR_2016_paper.pdf

The Unreasonable Effectiveness of Recurrent Neural Networks
http://karpathy.github.io/2015/05/21/rnn-effectiveness/

Minimal character-level language model with a Vanilla Recurrent Neural Network, in Python/numpy
https://gist.github.com/karpathy/d4dee566867f8291f086

Cho et al., 2014 (pdf)
http://arxiv.org/abs/1406.1078

RNN チュートリアル 
http://tensorflow.classcat.com/2016/03/13/tensorflow-cc-recurrent-neural-networks/

Sutskever et al., 2014 (pdf)
http://arxiv.org/abs/1409.3215

Bahdanau et al., 2014 (pdf) 
http://arxiv.org/abs/1409.0473

Bengio et al., 2015 (pdf) 
http://arxiv.org/abs/1506.03099

Jean et. al., 2014 (pdf) 
http://arxiv.org/abs/1412.2007

Sutskever et al., 2014 (pdf)
http://arxiv.org/abs/1409.3215

WMT'15 Website 
http://www.statmt.org/wmt15/translation-task.html

Vinyals & Kaiser et al., 2014 (pdf) 
http://arxiv.org/abs/1412.7449

Distributional Hypothesis（分布仮説）
https://en.wikipedia.org/wiki/Distributional_semantics#Distributional_Hypothesis

count-based メソッド（例えば潜在的意味解析, Latent Semantic Analysis）
https://en.wikipedia.org/wiki/Latent_semantic_analysis

予測的 (predictive) メソッド（例えば、確率的ニューラル言語モデル, neural probabilistic language models）
http://www.scholarpedia.org/article/Neural_net_language_models

Baroni et al.
http://clic.cimec.unitn.it/marco/publications/acl2014/baroni-etal-countpredict-acl2014.pdf
 
softmax 関数 
https://en.wikipedia.org/wiki/Softmax_function

最尤 (maximum likelihood (ML)) 原理
https://en.wikipedia.org/wiki/Maximum_likelihood

noise-contrastive estimation (NCE) 
http://papers.nips.cc/paper/5165-learning-word-embeddings-efficiently-with-noise-contrastive-estimation.pdf

Mikolov et al., 2013 
http://www.aclweb.org/anthology/N13-1090

Collobert et al., 2011 (pdf)
http://arxiv.org/abs/1103.0398

Turian et al., 2010
http://www.aclweb.org/anthology/P10-1040

埋め込みを評価する: 類推による推論 (Analogical Reasoning)
https://word2vec.googlecode.com/svn/trunk/questions-words.txt



</pre>
